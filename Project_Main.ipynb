{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "\n",
    "NEG_DIRECTORY_PATH = './review_polarity/txt_sentoken/neg'\n",
    "POS_DIRECTORY_PATH = './review_polarity/txt_sentoken/pos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Text Data\n",
    "\n",
    "1. iterate through negative and positive text files\n",
    "\n",
    "2. concat all lines per file to a single string\n",
    "\n",
    "3. create tensor dataset from list of strings\n",
    "\n",
    "4. label tensor dataset with 0 - negative | 1 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data_sets = []\n",
    "\n",
    "neg_file_names = list(os.listdir(NEG_DIRECTORY_PATH))\n",
    "pos_file_names = list(os.listdir(POS_DIRECTORY_PATH))\n",
    "\n",
    "lines_list = []\n",
    "for file_name in neg_file_names:\n",
    "  file = open(os.path.join(NEG_DIRECTORY_PATH, file_name))\n",
    "  lines = ''\n",
    "  for line in file:\n",
    "    lines += line.rstrip() + ' '\n",
    "  lines_list.append(lines)\n",
    "  file.close()\n",
    "\n",
    "lines_dataset = tf.data.Dataset.from_tensor_slices(lines_list)\n",
    "labeled_data_set = lines_dataset.map(lambda ex: (ex, 0))\n",
    "labeled_data_sets.append(labeled_data_set)\n",
    "\n",
    "lines_list = []\n",
    "for file_name in pos_file_names:\n",
    "  file = open(os.path.join(POS_DIRECTORY_PATH, file_name))\n",
    "  lines = ''\n",
    "  for line in file:\n",
    "    lines += line.rstrip() + ' '\n",
    "  lines_list.append(lines)\n",
    "  file.close()\n",
    "\n",
    "lines_dataset = tf.data.Dataset.from_tensor_slices(lines_list)\n",
    "labeled_data_set = lines_dataset.map(lambda ex: (ex, 1))\n",
    "labeled_data_sets.append(labeled_data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "1. Concat positive and negative reviews\n",
    "2. Double check size of full dataset\n",
    "3. Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 250\n",
    "\n",
    "#all_labeled_data = labeled_data_sets[0].concatenate(labeled_data_sets[1])\n",
    "neg_labeled_data = labeled_data_sets[0]\n",
    "pos_labeled_data = labeled_data_sets[1]\n",
    "print(len(neg_file_names))\n",
    "print(len(pos_file_names))\n",
    "#print(len(list(all_labeled_data)))\n",
    "\n",
    "pos_labeled_data = pos_labeled_data.shuffle(\n",
    "    BUFFER_SIZE, reshuffle_each_iteration=False)\n",
    "neg_labeled_data = neg_labeled_data.shuffle(\n",
    "    BUFFER_SIZE, reshuffle_each_iteration=False)\n",
    "\n",
    "print(len(list(neg_labeled_data)))\n",
    "print(len(list(pos_labeled_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=41384, shape=(), dtype=string, numpy=b'one of the responses those that enjoy \" detroit rock city \" ( probably kiss fans , mostly ) might have upon first glance at the rating i\\'ve given the film might be something like : \" oh , that casey\\'s gone and become a jaded critic on us . just what did he expect out of a dumb teenage rock n\\' roll movie like this ? \" i\\'m wondering the same thing . i feel like i should have had a grand time with \" detroit rock city . \" it\\'s the sort of movie i wish i could\\'ve had a lot of fun with , but i didn\\'t . i just didn\\'t . surely this film isn\\'t trying to win any major awards , so should i have expected an oscar-caliber film ? no , but i expected something . a funny joke . a clever prank . a plot development . anything . the movie never delivers . you\\'ve got to marvel at how the filmmakers managed to come up with a movie that is truly about nothing .  \" detroit rock city \" is one of those films that you walk out of after the credits have rolled and realize that you just spent 90 minutes watching a movie in which absolutely nothing happened to justify the film\\'s existence , and it\\'s not a very satisfying realization . the film is about four teenage boys , all huge kiss fans from cleveland , trying to get into a kiss concert in detroit , michigan . that\\'s it . there is no big plot description in this review , because the movie has very little plot . the characters are hawk ( edward furlong ) , lex ( giuseppe andrews ) , trip ( james debello ) , and jam ( sam huntington ) . they have a garage band . they\\'re pathetic , like all garage bands , but they like kiss and they like rock n\\' roll , so i guess that means we root for them . they have tickets , they lose them . they get more tickets , they lose those too . they come up with crazy schemes to get tickets , most of which backfire . there\\'s not much more to it . frankly , it becomes a little less than exciting to see them try to get kiss tickets about halfway through the film , when a total of eight tickets have already graced the boys\\' hands , only to be lost because of their sheer stupidity . oh , and jam ( real name jeremiah ) has a really , really annoying ultra-religious mother who ought to be reported to the child welfare agency . she doesn\\'t want them to see kiss , if you hadn\\'t figured that out already . it\\'s really quite disheartening to see such a fine soundtrack go to waste in a pointless movie like this . we\\'ve got plenty of kiss , along with some ac/dc , ramones , and thin lizzy . then again , \" maximum overdrive \" had an awesome soundtrack ( me being the big ac/dc fan that i am ) , but is probably one of the worst movies of all time .  \" detroit rock city \" doesn\\'t quite reach that level of ineptitude , but it gets dangerously close . in fact , the music is the only thing that keeps this movie from being a complete failure in my mind . basically , the soundtrack has earned the film a full half-star , which means all the bands involved can pat themselves on the back ( except for marilyn manson , whose half-hearted cover of ac/dc\\'s \" highway to hell \" sounds like something my neighbor\\'s cat coughed up ) . it\\'s also really sad to see the talents of the cast go to waste , because it\\' s evident that they\\'re all trying really hard to squeeze some life out of this dead turkey of a movie . edward furlong has done far better work than this , and so has natasha lyonne , and so has lin shaye , but hey , they\\'ve got to make a living in hollywood . people wanting to see kiss , and lots of it will probably be disappointed , considering the band appears for about five minutes and plays one song . too bad , they might have provided some energy to this mess . director adam rifkin knows he hasn\\'t got much material to work with , so he takes a chapter from the michael bay book of directing and keeps his camera spinning . we get an endless parade of quick-cuts , split-screens , zoom-outs , zoom-ins , and rotating cameras , all in an effort to cover up the sheer stupidity of the script . it\\'s fun for a while , but eventually it becomes disorienting . i would recommend that those who felt seasick at \" the blair witch project \" stay far away from \" detroit rock city , \" because the witch has got nothing on this baby . i haven\\'t felt such an urge to reach out and hold the camera still since \" armageddon . \" and what about that script ? it\\'s written by carl j . dupr ? , which sounds like as made-up a name as i\\'ve ever heard . if it is , i can\\'t say i blame the writer for distancing himself as far from this script as possible . a plotless , pointless rock n\\' roll movie can be fun , if the jokes and gags are actually funny . the jokes in \" detroit rock city \" rarely are . in fact , the only time i really laughed was when a priest gets stoned on a marijuana-laced pizza , and that was just because it was so surreal . the rest of the movie just seems like they just threw a bunch of vulgar stuff up on screen and called it \" comedy . \" there is no set-up , just a succession of punchlines that don\\'t provide for much in the way of chuckles , precisely because there was no set-up . it\\'s as if they just whacked someone on the head , pointed at him and said , \" see ? funny ! \" look , that woman was so shocked by hearing loud kiss music that she spilled her drink . see ? funny ! look , that guy just got clocked by a telephone receiver . twice . see ? funny ! look , that kid has been vomiting for 20 minutes after drinking an inordinate amount of alcohol and is now about to perform an exotic dance for money . see ? funny ! a word of advice to mr . dupr ? : no , these things aren\\'t funny all by themselves . they must be preceded by a clever set-up so the audience hasn \\'t predicted them five minutes in advance . that\\'s it , i\\'ve said enough about this movie . it\\'s a waste of time and money . i liked the music , but don\\'t bother buying the soundtrack . i hear it\\' s just modern bands doing inferior versions of the songs that are actually in the movie . you want to see this concept executed well ? go rent roger corman\\'s 1979 classic \" rock n\\' roll high school . \" it features another late-seventies rock band ( the ramones ) and a far more interesting story about a girl trying to get tickets to their show . yes , go rent that , and skip \" detroit rock city , \" which will probably bomb , and deservedly so . '>, <tf.Tensor: id=41385, shape=(), dtype=int32, numpy=0>)\n",
      "--------------\n",
      "(<tf.Tensor: id=41393, shape=(), dtype=string, numpy=b'jerry springer has got nothing on \" wild things . \" john mcnaughton\\'s new thriller tackles more tawdry themes in less than two hours than springer\\'s notoriously sleazy talk show broadcasts in two weeks -- bisexuality , threesomes , poolside catfights , slutty rich bimbos , even redneck gator-wrestling , they\\'re all part of the movie\\'s raucous , complex storyline . but even trash tv topicality can\\'t drag \" wild things \" down -- this crazy campfest plays like something you\\'d find late-night on the usa network , only infinitely more palatable and with a solid ensemble cast . despite a smattering of needless scenes ( most of them sexual in nature ) , there\\'s wicked fun to be had here .  \" wild things \" would be a guilty pleasure , only there\\'s no guilty feeling involved in having a good time with it . high school guidance counselor sam lombardo ( matt dillon ) is well-liked in the town of blue bay , especially by pretty , popular kelly van ryan ( denise richards ) , whose family name is among the florida yachting enclave\\'s most financially prominent . hoping to take her crush to a physical level , kelly seductively slinks into lombardo\\'s house after washing his jeep for a fundraiser , but , the very next day , tearfully admits to her trollop mother ( theresa russell ) that she was raped . before long , blue bay detectives ray duquette ( kevin bacon ) and gloria perez ( daphne rubin-vega ) are listening to similar allegations from kelly\\'s rebel classmate suzie toller ( neve campbell ) . lombardo , who maintains his innocence , hires neck brace-sporting , opportunistic lawyer ken bowden ( bill murray ) to defend him in court . the previews give away the following revelations , so if you haven\\'t seen any of the movie\\'s spots on the television or in the theater , you might want to skip to the next paragraph . while cross-examining suzie on the witness stand , bowden gets her to break down and admit that the alleged rapes never took place -- that kelly had concocted this entire scheme because she was angry that lombardo was sleeping with her mother and not with her . to pay lombardo for the damages , kelly\\'s mother breaks her daughter\\'s trust fund and gives him $8 . 5 million . but lombardo , kelly and suzie are actually all working together , and plan to take the money and run as fast as they can . duquette and perez , however , begin to suspect that there\\'s more afoot to the case than just false accusations . if there\\'s a major drawback to \" wild things , \" it\\'s that it\\'s oversexed to a fault . the much-talked-about hotel room menage-a-trois between dillon , campbell and richards is a turn-off . it\\'s also cut short ( sorry , guys ) , and should have been cut shorter -- the movie grinds to a halt for pure titillation once too often . what we don\\'t see is far more effective than what we do . another example of this is kevin bacon needlessly going the full monty in a shower scene . er , no thanks . also , bacon\\'s duquette feels simultaneously underdeveloped and overwritten . daphne rubin-vega , from broadway\\'s \" rent , \" tries to compensate for a superfluous character . theresa russell is just plain wooden . and when , in the end , all is out in the open , ask yourself if certain scenes involving these three were really necessary . but what keeps the movie from being throwaway junk is an engaging chain of surprises ( some predictable , some not ) that never seems to end .  \" wild things \" has more twists than a crate full of corkscrews , and most are so gleefully , over-the-top nasty that you can\\'t help but be charmed by their absurd showmanship . a great deal of amusement also comes from watching bill murray in a supporting part that appears to have been written for his sly comedic talent ; murray\\'s a stitch , especially when pulling up beside the van ryan limo after winning lombardo\\'s case and flipping them off . and don\\'t leave when the closing credits hit the screen , or you\\'ll miss the film\\'s best part -- four bonus flashbacks that smooth over plot holes while offering a few more tiny turns , plus a final scene that caps everything off with a great stunner of a bombshell . speaking of bombshells , denise richards , who plays almost every scene in a blue bikini top , does the teen tease thing with a malicious allure that she was never allowed to flaunt in \" starship troopers . \" matt dillon flexes his sleepy-voiced sex appeal , and pulls off personality changes with chameleonic precision . neve campbell , lovely as ever except when sporting a blond wig , gives suzie a vengeful vulnerability that makes her the most interesting member of the conspiring trio . re-edited and toned down a bit , the dynamics between these three actors could have carried the film to greater lengths . but what we\\'re given works well enough .  \" wild things \" is highly entertaining and , indeed , very wild . '>, <tf.Tensor: id=41394, shape=(), dtype=int32, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "for ex in neg_labeled_data.take(1):\n",
    "  print(ex)\n",
    "print(\"--------------\")\n",
    "for ex in pos_labeled_data.take(1):\n",
    "  print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Encode Words\n",
    "\n",
    "1. Get unique vocabulary set among data\n",
    "2. Create encoder based on vocabulary set\n",
    "3. Encode data text -> int using vocabulary as dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39696"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "vocabulary_set = set()\n",
    "for text_tensor, _ in neg_labeled_data:\n",
    "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
    "  vocabulary_set.update(some_tokens)\n",
    "\n",
    "for text_tensor, _ in pos_labeled_data:\n",
    "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
    "  vocabulary_set.update(some_tokens)\n",
    "\n",
    "vocab_size = len(vocabulary_set)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'jerry springer has got nothing on \" wild things . \" john mcnaughton\\'s new thriller tackles more tawdry themes in less than two hours than springer\\'s notoriously sleazy talk show broadcasts in two weeks -- bisexuality , threesomes , poolside catfights , slutty rich bimbos , even redneck gator-wrestling , they\\'re all part of the movie\\'s raucous , complex storyline . but even trash tv topicality can\\'t drag \" wild things \" down -- this crazy campfest plays like something you\\'d find late-night on the usa network , only infinitely more palatable and with a solid ensemble cast . despite a smattering of needless scenes ( most of them sexual in nature ) , there\\'s wicked fun to be had here .  \" wild things \" would be a guilty pleasure , only there\\'s no guilty feeling involved in having a good time with it . high school guidance counselor sam lombardo ( matt dillon ) is well-liked in the town of blue bay , especially by pretty , popular kelly van ryan ( denise richards ) , whose family name is among the florida yachting enclave\\'s most financially prominent . hoping to take her crush to a physical level , kelly seductively slinks into lombardo\\'s house after washing his jeep for a fundraiser , but , the very next day , tearfully admits to her trollop mother ( theresa russell ) that she was raped . before long , blue bay detectives ray duquette ( kevin bacon ) and gloria perez ( daphne rubin-vega ) are listening to similar allegations from kelly\\'s rebel classmate suzie toller ( neve campbell ) . lombardo , who maintains his innocence , hires neck brace-sporting , opportunistic lawyer ken bowden ( bill murray ) to defend him in court . the previews give away the following revelations , so if you haven\\'t seen any of the movie\\'s spots on the television or in the theater , you might want to skip to the next paragraph . while cross-examining suzie on the witness stand , bowden gets her to break down and admit that the alleged rapes never took place -- that kelly had concocted this entire scheme because she was angry that lombardo was sleeping with her mother and not with her . to pay lombardo for the damages , kelly\\'s mother breaks her daughter\\'s trust fund and gives him $8 . 5 million . but lombardo , kelly and suzie are actually all working together , and plan to take the money and run as fast as they can . duquette and perez , however , begin to suspect that there\\'s more afoot to the case than just false accusations . if there\\'s a major drawback to \" wild things , \" it\\'s that it\\'s oversexed to a fault . the much-talked-about hotel room menage-a-trois between dillon , campbell and richards is a turn-off . it\\'s also cut short ( sorry , guys ) , and should have been cut shorter -- the movie grinds to a halt for pure titillation once too often . what we don\\'t see is far more effective than what we do . another example of this is kevin bacon needlessly going the full monty in a shower scene . er , no thanks . also , bacon\\'s duquette feels simultaneously underdeveloped and overwritten . daphne rubin-vega , from broadway\\'s \" rent , \" tries to compensate for a superfluous character . theresa russell is just plain wooden . and when , in the end , all is out in the open , ask yourself if certain scenes involving these three were really necessary . but what keeps the movie from being throwaway junk is an engaging chain of surprises ( some predictable , some not ) that never seems to end .  \" wild things \" has more twists than a crate full of corkscrews , and most are so gleefully , over-the-top nasty that you can\\'t help but be charmed by their absurd showmanship . a great deal of amusement also comes from watching bill murray in a supporting part that appears to have been written for his sly comedic talent ; murray\\'s a stitch , especially when pulling up beside the van ryan limo after winning lombardo\\'s case and flipping them off . and don\\'t leave when the closing credits hit the screen , or you\\'ll miss the film\\'s best part -- four bonus flashbacks that smooth over plot holes while offering a few more tiny turns , plus a final scene that caps everything off with a great stunner of a bombshell . speaking of bombshells , denise richards , who plays almost every scene in a blue bikini top , does the teen tease thing with a malicious allure that she was never allowed to flaunt in \" starship troopers . \" matt dillon flexes his sleepy-voiced sex appeal , and pulls off personality changes with chameleonic precision . neve campbell , lovely as ever except when sporting a blond wig , gives suzie a vengeful vulnerability that makes her the most interesting member of the conspiring trio . re-edited and toned down a bit , the dynamics between these three actors could have carried the film to greater lengths . but what we\\'re given works well enough .  \" wild things \" is highly entertaining and , indeed , very wild . '\n",
      "--------------------------------\n",
      "b'one of the responses those that enjoy \" detroit rock city \" ( probably kiss fans , mostly ) might have upon first glance at the rating i\\'ve given the film might be something like : \" oh , that casey\\'s gone and become a jaded critic on us . just what did he expect out of a dumb teenage rock n\\' roll movie like this ? \" i\\'m wondering the same thing . i feel like i should have had a grand time with \" detroit rock city . \" it\\'s the sort of movie i wish i could\\'ve had a lot of fun with , but i didn\\'t . i just didn\\'t . surely this film isn\\'t trying to win any major awards , so should i have expected an oscar-caliber film ? no , but i expected something . a funny joke . a clever prank . a plot development . anything . the movie never delivers . you\\'ve got to marvel at how the filmmakers managed to come up with a movie that is truly about nothing .  \" detroit rock city \" is one of those films that you walk out of after the credits have rolled and realize that you just spent 90 minutes watching a movie in which absolutely nothing happened to justify the film\\'s existence , and it\\'s not a very satisfying realization . the film is about four teenage boys , all huge kiss fans from cleveland , trying to get into a kiss concert in detroit , michigan . that\\'s it . there is no big plot description in this review , because the movie has very little plot . the characters are hawk ( edward furlong ) , lex ( giuseppe andrews ) , trip ( james debello ) , and jam ( sam huntington ) . they have a garage band . they\\'re pathetic , like all garage bands , but they like kiss and they like rock n\\' roll , so i guess that means we root for them . they have tickets , they lose them . they get more tickets , they lose those too . they come up with crazy schemes to get tickets , most of which backfire . there\\'s not much more to it . frankly , it becomes a little less than exciting to see them try to get kiss tickets about halfway through the film , when a total of eight tickets have already graced the boys\\' hands , only to be lost because of their sheer stupidity . oh , and jam ( real name jeremiah ) has a really , really annoying ultra-religious mother who ought to be reported to the child welfare agency . she doesn\\'t want them to see kiss , if you hadn\\'t figured that out already . it\\'s really quite disheartening to see such a fine soundtrack go to waste in a pointless movie like this . we\\'ve got plenty of kiss , along with some ac/dc , ramones , and thin lizzy . then again , \" maximum overdrive \" had an awesome soundtrack ( me being the big ac/dc fan that i am ) , but is probably one of the worst movies of all time .  \" detroit rock city \" doesn\\'t quite reach that level of ineptitude , but it gets dangerously close . in fact , the music is the only thing that keeps this movie from being a complete failure in my mind . basically , the soundtrack has earned the film a full half-star , which means all the bands involved can pat themselves on the back ( except for marilyn manson , whose half-hearted cover of ac/dc\\'s \" highway to hell \" sounds like something my neighbor\\'s cat coughed up ) . it\\'s also really sad to see the talents of the cast go to waste , because it\\' s evident that they\\'re all trying really hard to squeeze some life out of this dead turkey of a movie . edward furlong has done far better work than this , and so has natasha lyonne , and so has lin shaye , but hey , they\\'ve got to make a living in hollywood . people wanting to see kiss , and lots of it will probably be disappointed , considering the band appears for about five minutes and plays one song . too bad , they might have provided some energy to this mess . director adam rifkin knows he hasn\\'t got much material to work with , so he takes a chapter from the michael bay book of directing and keeps his camera spinning . we get an endless parade of quick-cuts , split-screens , zoom-outs , zoom-ins , and rotating cameras , all in an effort to cover up the sheer stupidity of the script . it\\'s fun for a while , but eventually it becomes disorienting . i would recommend that those who felt seasick at \" the blair witch project \" stay far away from \" detroit rock city , \" because the witch has got nothing on this baby . i haven\\'t felt such an urge to reach out and hold the camera still since \" armageddon . \" and what about that script ? it\\'s written by carl j . dupr ? , which sounds like as made-up a name as i\\'ve ever heard . if it is , i can\\'t say i blame the writer for distancing himself as far from this script as possible . a plotless , pointless rock n\\' roll movie can be fun , if the jokes and gags are actually funny . the jokes in \" detroit rock city \" rarely are . in fact , the only time i really laughed was when a priest gets stoned on a marijuana-laced pizza , and that was just because it was so surreal . the rest of the movie just seems like they just threw a bunch of vulgar stuff up on screen and called it \" comedy . \" there is no set-up , just a succession of punchlines that don\\'t provide for much in the way of chuckles , precisely because there was no set-up . it\\'s as if they just whacked someone on the head , pointed at him and said , \" see ? funny ! \" look , that woman was so shocked by hearing loud kiss music that she spilled her drink . see ? funny ! look , that guy just got clocked by a telephone receiver . twice . see ? funny ! look , that kid has been vomiting for 20 minutes after drinking an inordinate amount of alcohol and is now about to perform an exotic dance for money . see ? funny ! a word of advice to mr . dupr ? : no , these things aren\\'t funny all by themselves . they must be preceded by a clever set-up so the audience hasn \\'t predicted them five minutes in advance . that\\'s it , i\\'ve said enough about this movie . it\\'s a waste of time and money . i liked the music , but don\\'t bother buying the soundtrack . i hear it\\' s just modern bands doing inferior versions of the songs that are actually in the movie . you want to see this concept executed well ? go rent roger corman\\'s 1979 classic \" rock n\\' roll high school . \" it features another late-seventies rock band ( the ramones ) and a far more interesting story about a girl trying to get tickets to their show . yes , go rent that , and skip \" detroit rock city , \" which will probably bomb , and deservedly so . '\n"
     ]
    }
   ],
   "source": [
    "example_text = next(iter(pos_labeled_data))[0].numpy()\n",
    "print(example_text)\n",
    "print(\"--------------------------------\")\n",
    "example_text = next(iter(neg_labeled_data))[0].numpy()\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34252, 8614, 13535, 24262, 14969, 16878, 3983, 7078, 27837, 24393, 8024, 14139, 26408, 15541, 18348, 25622, 10904, 5014, 11337, 30048, 13535, 20372, 17742, 35658, 26566, 13535, 19492, 18348, 3008, 7178, 23642, 16612, 16878, 17763, 2424, 37628, 4479, 20022, 10988, 25420, 32245, 21555, 19217, 4220, 34068, 29771, 18051, 30799, 7422, 8614, 10988, 38739, 4168, 27837, 18562, 23357, 192, 23642, 3975, 17742, 6773, 22230, 13535, 28599, 11627, 17742, 17107, 23642, 17742, 7085, 25622, 3031, 10988, 5432, 5083, 27241, 7078, 27837, 24393, 19235, 2424, 13535, 11799, 8614, 192, 17742, 38529, 17742, 11688, 35658, 3031, 10988, 38280, 8614, 13496, 27241, 19742, 17742, 34031, 2182, 17742, 4220, 34031, 2182, 21629, 3975, 19492, 34377, 2182, 23458, 23353, 3754, 31752, 7023, 17397, 22551, 7085, 17742, 25622, 7338, 39387, 19283, 8914, 19492, 28363, 19742, 17742, 7338, 7178, 10988, 33883, 922, 10988, 26852, 9092, 10988, 27713, 8428, 24039, 13535, 192, 9502, 2391, 14325, 35658, 25067, 23353, 19503, 30048, 13372, 13535, 1435, 23912, 23353, 37818, 28091, 27241, 10988, 192, 16878, 23533, 9348, 16702, 28716, 7078, 27837, 24393, 23533, 34252, 8614, 14969, 14901, 16878, 14325, 16591, 7422, 8614, 22979, 13535, 17417, 25622, 27281, 4479, 9581, 16878, 14325, 4220, 8546, 10085, 29138, 32151, 10988, 192, 37926, 7391, 9341, 28716, 36914, 23353, 28329, 13535, 19492, 2424, 11349, 4479, 19235, 2424, 26258, 10988, 324, 32260, 38813, 13535, 19492, 23533, 16702, 30246, 4168, 1559, 21846, 2364, 14139, 26408, 21741, 3069, 23458, 23353, 34089, 24578, 10988, 14139, 34496, 37926, 7078, 22206, 16878, 2424, 19235, 15780, 23533, 28363, 11102, 27713, 37528, 37926, 3975, 12163, 27057, 13535, 192, 38012, 324, 35613, 27713, 13535, 4193, 28682, 29443, 2063, 2777, 34655, 38516, 3397, 13411, 7427, 28042, 4479, 8835, 460, 11392, 9377, 25622, 10988, 14271, 27156, 9377, 15334, 20917, 23642, 21846, 14271, 19064, 19742, 9377, 23642, 14139, 4479, 9377, 23642, 27837, 18562, 23357, 22551, 17742, 12233, 16878, 28239, 12059, 33127, 23486, 34896, 9377, 25622, 20792, 9377, 15160, 34896, 9377, 34089, 15076, 20792, 9377, 15160, 14969, 17419, 9377, 37818, 28091, 27241, 24731, 27028, 23353, 34089, 20792, 141, 8614, 7391, 24011, 15780, 2424, 26258, 27308, 15076, 23353, 19235, 898, 19235, 5433, 10988, 35613, 7359, 29228, 8717, 23353, 20649, 34896, 29630, 23353, 34089, 14139, 20792, 16702, 4503, 27238, 13535, 19492, 9207, 10988, 38040, 8614, 27556, 20792, 25622, 34703, 28527, 13535, 1559, 1924, 31101, 23353, 3008, 34588, 27057, 8614, 5724, 39108, 24400, 16612, 4479, 8835, 14665, 39582, 35011, 38012, 10988, 29054, 29054, 15652, 28168, 18025, 39051, 5249, 20820, 23353, 3008, 15012, 23353, 13535, 15938, 32232, 5970, 6714, 24980, 2182, 28237, 34896, 23353, 20649, 14139, 2753, 14325, 10282, 2182, 943, 16878, 7422, 34703, 19235, 2424, 29054, 5938, 19639, 23353, 20649, 38833, 10988, 7917, 7931, 37077, 23353, 2594, 37926, 10988, 13876, 192, 23642, 3975, 12059, 35658, 25067, 34107, 8614, 14139, 1511, 27241, 14664, 12843, 30665, 23612, 4479, 6194, 1283, 9628, 3651, 23886, 25649, 3031, 39387, 17461, 7931, 35051, 2104, 13535, 11102, 12843, 30665, 13559, 16878, 17742, 16488, 19742, 23533, 8024, 34252, 8614, 13535, 24801, 19335, 8614, 21846, 5083, 7078, 27837, 24393, 24980, 2182, 5938, 3823, 16878, 20236, 8614, 28732, 19742, 19235, 6170, 24995, 17071, 37926, 28343, 13535, 32983, 23533, 13535, 31101, 11627, 16878, 6337, 3975, 192, 21741, 2104, 10988, 39597, 15971, 37926, 3539, 15340, 32437, 13535, 7931, 38012, 30371, 13535, 19492, 10988, 9608, 34895, 14227, 7391, 28239, 21846, 13535, 19064, 9740, 13271, 36063, 6981, 21555, 13535, 10754, 37861, 23486, 28177, 30182, 644, 34895, 19262, 36478, 8614, 12843, 30665, 2424, 22043, 23353, 32206, 17306, 23642, 7178, 3539, 21796, 2424, 33624, 8111, 28091, 19235, 2424, 30331, 29054, 35309, 23353, 20649, 13535, 37043, 8614, 13535, 30248, 37077, 23353, 2594, 27057, 19235, 2424, 34142, 16878, 9377, 15334, 21846, 23458, 29054, 9197, 23353, 26087, 14664, 13545, 7422, 8614, 3975, 18837, 20081, 8614, 10988, 192, 2063, 2777, 38012, 27354, 7800, 34596, 29359, 29228, 3975, 4479, 22551, 38012, 34718, 33750, 4479, 22551, 38012, 5698, 30778, 19742, 18913, 9377, 35658, 25067, 23353, 8510, 10988, 17253, 37926, 108, 33262, 7612, 23353, 20649, 14139, 4479, 13160, 8614, 19235, 3920, 8024, 3008, 13364, 18939, 13535, 27156, 9389, 23486, 16702, 23690, 29138, 4479, 34720, 34252, 10606, 17419, 16326, 9377, 18348, 25622, 22062, 14664, 16192, 23353, 3975, 10234, 36515, 16102, 14746, 34467, 18051, 30219, 2182, 25067, 27308, 12375, 23353, 29359, 27241, 22551, 18051, 22192, 10988, 10111, 21741, 13535, 23838, 30834, 33494, 8614, 22200, 4479, 6337, 19505, 22288, 19350, 12059, 34089, 39387, 38862, 938, 8614, 34235, 11092, 28399, 2442, 13910, 24413, 13910, 20590, 4479, 2859, 2599, 21846, 37926, 39387, 33272, 23353, 36478, 28091, 13535, 39108, 24400, 8614, 13535, 33108, 19235, 2424, 13496, 23486, 10988, 38899, 19742, 10935, 19235, 5433, 22402, 17742, 10787, 32248, 16878, 14969, 5249, 9479, 19953, 30048, 13535, 27483, 34795, 37526, 5086, 7800, 18484, 21741, 7078, 27837, 24393, 27057, 13535, 34795, 38012, 25067, 28716, 21555, 3975, 24001, 17742, 27271, 2182, 9479, 38833, 39387, 14784, 23353, 3823, 7422, 4479, 15525, 13535, 22288, 25027, 38354, 32308, 4479, 34068, 16702, 16878, 33108, 19235, 2424, 15247, 16472, 9054, 7446, 7660, 7391, 17306, 23642, 29264, 9603, 28091, 10988, 39582, 29264, 17742, 35658, 13632, 37478, 2753, 19235, 23533, 17742, 13271, 2182, 10075, 17742, 17992, 13535, 5807, 23486, 35628, 20145, 29264, 7800, 21741, 3975, 33108, 29264, 9340, 10988, 14184, 13876, 27837, 18562, 23357, 192, 13271, 3008, 13496, 2753, 13535, 36401, 4479, 28368, 28682, 28964, 33883, 13535, 36401, 37926, 7078, 27837, 24393, 17970, 28682, 37926, 28343, 13535, 31101, 5083, 17742, 29054, 14172, 31927, 9207, 10988, 3965, 6170, 34025, 21555, 10988, 37964, 22905, 17165, 4479, 16878, 31927, 4220, 27057, 19235, 31927, 22551, 23338, 13535, 13094, 8614, 13535, 192, 4220, 36575, 23642, 9377, 4220, 25442, 10988, 34206, 8614, 19038, 10174, 28091, 21555, 38842, 4479, 22274, 19235, 1989, 15780, 23533, 28363, 36466, 28091, 4220, 10988, 39006, 8614, 18240, 16878, 37626, 2182, 24726, 23486, 27308, 37926, 13535, 27007, 8614, 5462, 23294, 27057, 15780, 31927, 28363, 36466, 28091, 19235, 2424, 29264, 2753, 9377, 4220, 29247, 35281, 21555, 13535, 3820, 23453, 30048, 16522, 4479, 25942, 20649, 33883, 13684, 16878, 24125, 31927, 22551, 31531, 16472, 15623, 14320, 14139, 32983, 16878, 6714, 8936, 2038, 8336, 20649, 33883, 13684, 16878, 26055, 4220, 25067, 23995, 16472, 10988, 29995, 19473, 32993, 20649, 33883, 13684, 16878, 35918, 38012, 35504, 4579, 23486, 21272, 29138, 22979, 3744, 39387, 39363, 20847, 8614, 8505, 4479, 23533, 6265, 16702, 23353, 24710, 39387, 10777, 31176, 23486, 29916, 20649, 33883, 10988, 20075, 8614, 6835, 23353, 13712, 7660, 28363, 12766, 1367, 28948, 2182, 33883, 21846, 16472, 6981, 9377, 8677, 3008, 11033, 16472, 10988, 26852, 36466, 28091, 22551, 13535, 7943, 30219, 2182, 36894, 34896, 23690, 29138, 37926, 34403, 16878, 2424, 19235, 17742, 35658, 25942, 35327, 16702, 3975, 192, 19235, 2424, 10988, 2594, 8614, 5083, 4479, 29916, 17742, 15175, 13535, 32983, 19742, 37626, 2182, 32251, 29667, 13535, 7931, 17742, 25244, 19235, 2424, 4220, 3003, 19064, 19119, 18251, 6201, 8614, 13535, 5294, 16878, 28682, 28964, 37926, 13535, 192, 14325, 28237, 23353, 20649, 3975, 18530, 19433, 23449, 37077, 18869, 4572, 15697, 2424, 570, 39040, 27837, 18562, 23357, 30000, 28498, 19235, 29101, 31588, 37942, 22095, 27837, 27156, 13535, 23612, 4479, 10988, 7800, 15076, 29414, 9173, 16702, 10988, 22624, 23458, 23353, 34089, 20792, 23353, 5724, 19352, 29678, 37077, 18869, 16878, 4479, 38296, 7078, 27837, 24393, 7391, 3920, 8024, 37487, 4479, 7255, 22551]\n"
     ]
    }
   ],
   "source": [
    "encoded_example = encoder.encode(example_text)\n",
    "print(encoded_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text_tensor, label):\n",
    "  encoded_text = encoder.encode(text_tensor.numpy())\n",
    "  return encoded_text, label\n",
    "\n",
    "def encode_map_fn(text, label):\n",
    "  # py_func doesn't set the shape of the returned tensors.\n",
    "  encoded_text, label = tf.py_function(encode, \n",
    "                                       inp=[text, label], \n",
    "                                       Tout=(tf.int64, tf.int32))\n",
    "\n",
    "  return encoded_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4084 33198 38012 25067 28716 21555 32927  1367 12267 11746  2424 12851\n",
      "  7777 16416 15076 10460 11230 37926  7359 29228 27313 16565 29228 33198\n",
      "  2424 18741 12811 35087 19352 23081 37926 27313  7544 31294  7578  8492\n",
      " 13417  5596  5363   322 17433 31311 31020 16388  9377 15334 21846 11948\n",
      "  8614 13535   192  2424 31025 24104 37411 19742 17433 35028 22275  6681\n",
      " 13271  2182  4085 32927  1367 23196  3975 24731 23643 34720 23642  7178\n",
      " 14325 13664 31496 37942 39311 21555 13535 22984 17581 31101 24922 15076\n",
      " 33366  4479 27241 10988 21859 17881 30248 22466 10988 39447  8614 19961\n",
      "  9528   141  8614 34896  1848 37926 28170 15780  2424 30254 13496 23353\n",
      "  3008  3031 11569 32927  1367 10787  3008 10988 32763 21493 31101 15780\n",
      "  2424 28363 32763 29487  9740 37926 38908 10988 13293  5083 27241 19235\n",
      " 30000 28498 22722 19506   460 34028 21169 39692 23533 23449 15175 37926\n",
      " 13535 37714  8614  8852 30834  1235 16472 35903 16128 20622  4038 35380\n",
      " 20740  4375   644  4458 39582 23533 33545 13535  4953 21475   951  2424\n",
      "   141 34806 22018  1130 23353 21898  2038 35393 23353 10988 18315 20236\n",
      " 20622 11342 17156 24578 34028  2424 21777 22979   314 19505  2886 23486\n",
      " 10988 14909 19742 13535   324  2433 18729  2947 35799 23353  2038 21325\n",
      " 39051 38047 15550 16878  6714 31927 21776 10165 26975  8852 30834 18387\n",
      " 23611   398 17230 18682  4479 30982 24464 22738 31051 12496 28682 37395\n",
      " 23353 18843 30590 21741 20622  2424 20360 34832 11689 19475  3187 25655\n",
      " 34028  5249 10923 19505 23307 30116 38557   201 20993 35552 17855 28027\n",
      " 39487 33241 30073 23353 17671 16522 37926 29012 13535 38680 34664 18484\n",
      " 13535 37506 33089 22551  2753 14325 27271  2182 37315 31752  8614 13535\n",
      "   192  2424 33463 21555 13535 32579 17806 37926 13535 22476 14325 18348\n",
      " 28237 23353 38296 23353 13535  2433  3484 38899 11850 10515 11689 21555\n",
      " 13535 36075 27778 39487  6170  2038 23353  7657 23196  4479 24588 16878\n",
      " 13535 38288 17841  9502 24023 39649 16878 20622  3031  8405  3975  3104\n",
      "   157 27057  6714 31927 17442 16878 34028 31927 29386 27241  2038 39051\n",
      "  4479 26258 27241  2038 23353 27157 34028 23486 13535 30366 20622  2424\n",
      " 39051 26755  2038 37199  2424 13978 17455  4479 22878 16522  6501 37836\n",
      " 15846 19742 34028 20622  4479 11689 28682 28964 21846 31424 24244  4479\n",
      " 27727 23353 21898 13535 29916  4479 22707 29264 32848 29264  9377 13271\n",
      "   398  4479 24464 20999 35160 23353 23903 16878 15780  2424 15076  6645\n",
      " 23353 13535 24630 29228  4220 15384 13184  2753 15780  2424 10988  7023\n",
      " 39102 23353 32927  1367 19235  2424 16878 19235  2424 31593 23353 10988\n",
      " 22591 13535 27308 12561 16702  4429  7173 16923 10988 31232 38505 39692\n",
      " 25655  4479  4375 23533 10988 34493 12760 19235  2424 30331 26694 39544\n",
      "  3985 23810  4479  7085 25622 35504 26694 29141 13535   192  1189 23353\n",
      " 10988 22015 23486 21595 38995 29001 17419 32882 34068 12059 37626  2182\n",
      " 20649 23533  7800 15076 38264 29228 34068 12059 28331 31588 28281  8614\n",
      "  3975 23533 17230 18682  6438  4023 13535  9608  7434 37926 10988 10516\n",
      " 20733 29343 28363   217 30331 18682  2424   398 35432 22425 29196  4479\n",
      " 22478 22738 31051 12496 21741 34011  2424 18869  3666 23353 38488 23486\n",
      " 10988  3561 35458 38047 15550 23533  4220  9960 27123  4479  9207 37926\n",
      " 13535 37329 21846 23533  7422 37926 13535  6469  2620 14288  2753 36579\n",
      "  9528 30196 12766 32842 38225 29054 28106 19742 34068  6337 13535   192\n",
      " 21741  2104 19769 11082 23533 39387 28631 26324  8614 21723 14664 30407\n",
      " 14664 26258 16878  9502 36575 23353 37329 32927  1367 38012 15076  6283\n",
      " 29228 10988 33382  9608  8614 27080  4479   141 28682 22551 23830 26193\n",
      " 13535 27732 22051 16878 14325 13271  2182 17225 19742  3008  5293 16472\n",
      "  5724  4754 32191 10988 24894 34629  8614  8418 30331 19763 21741 32151\n",
      " 33241 30073 37926 10988 18851 11948 16878  9389 23353 25622 35504 15247\n",
      " 23486 19505 18789 33500 33324 30073  2424 10988 13786  1235  9207 26872\n",
      " 28091 12393 13535  4038 35380 25074 22979 32014 34028  2424 24630  4479\n",
      " 29598 34896 12760  4479 37626  2182 25199  9207 13535 16476 17417  2639\n",
      " 13535 38842 17806 14325 25795   747 13535 19492  2424 24440 11948 30246\n",
      " 16074 35909 16878 28173 26193 27713 14440 38899  8794 10988 31023 15076\n",
      "  7773  7457  5949 10988 13161 20733 16878 39602 33536 12760 27241 10988\n",
      " 24894 17710  8614 10988   304 27490  8614 39336 20740  4375  5249 34720\n",
      "  1640 28297 20733 37926 10988  8852  8787 27732  3936 13535 12057  9141\n",
      " 11627 27241 10988 12085 25061 16878  6714 31927  9502  7180 23353 20027\n",
      " 37926 36110 39648 21169 39692 15792 19505 35727   116 21490 35063  4479\n",
      "  7281 12760 32918 15292 27241 13318 37152  3187 25655  4740 29264 13632\n",
      " 37861  9207 20993 10988 12502 22870 22878 11689 10988 36588 13149 16878\n",
      " 21334  2038 13535   141 29414 30059  8614 13535 15094  4430 15334  7020\n",
      "  4479  3422 23196 10988 14115 13535 34427 38505 12766 32842 21766 11688\n",
      " 25622 11438 13535 19492 23353 28188  3052 19742 34068 12059 15334 26566\n",
      " 39353 23449 35327 32927  1367 23533 28691 19500  4479  6534   324 32927]\n",
      "[34252  8614 13535 ...  4479  7255 22551]\n"
     ]
    }
   ],
   "source": [
    "pos_encoded_data = pos_labeled_data.map(encode_map_fn)\n",
    "\n",
    "example_encoding = next(iter(pos_encoded_data))[0].numpy()\n",
    "#x = next(iter(all_encoded_data))[1].numpy()\n",
    "print(example_encoding)\n",
    "\n",
    "neg_encoded_data = neg_labeled_data.map(encode_map_fn)\n",
    "\n",
    "example_encoding = next(iter(neg_encoded_data))[0].numpy()\n",
    "#x = next(iter(all_encoded_data))[1].numpy()\n",
    "print(example_encoding)\n",
    "#print(x)\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "TRAIN_AMT = 0.8\n",
    "BATCH_SIZE = 25\n",
    "\n",
    "take_size = math.ceil(len(list(pos_encoded_data)) * (1 - TRAIN_AMT))\n",
    "print(take_size)\n",
    "\n",
    "take_size = math.ceil(len(list(neg_encoded_data)) * (1 - TRAIN_AMT))\n",
    "print(take_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "train_data_pos = pos_encoded_data.skip(take_size).shuffle(BUFFER_SIZE)\n",
    "train_data_neg = neg_encoded_data.skip(take_size).shuffle(BUFFER_SIZE)\n",
    "#print(type(train_data_pos), type(train_data_neg))\n",
    "all_labeled_train_data = train_data_pos.concatenate(train_data_neg)\n",
    "#print(all_labeled_data)\n",
    "#for ex in all_labeled_data.take(1):\n",
    "#    print(ex)\n",
    "#print(len(list(all_labeled_data)))\n",
    "train_data = all_labeled_train_data.padded_batch(BATCH_SIZE, padded_shapes=([None],[]))\n",
    "\n",
    "test_data_pos = pos_encoded_data.take(take_size)\n",
    "test_data_neg = neg_encoded_data.take(take_size)\n",
    "all_labeled_test_data = test_data_pos.concatenate(test_data_neg)\n",
    "print(len(list(all_labeled_test_data)))\n",
    "test_data = all_labeled_test_data.padded_batch(BATCH_SIZE, padded_shapes=([None],[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "s_train = set()\n",
    "for text, labels in train_data:\n",
    "    #print(text[0].numpy(), labels[0].numpy())\n",
    "    s_train.add(labels[0].numpy())\n",
    "    \n",
    "s_test = set()\n",
    "for text, labels in test_data:\n",
    "    #print(text[0].numpy(), labels[0].numpy())\n",
    "    s_test.add(labels[0].numpy())\n",
    "print(s_train)\n",
    "print(s_test)\n",
    "#sample_text, sample_labels = next(iter(test_data))\n",
    "\n",
    "#print(sample_text)\n",
    "#sample_text[0].numpy(), sample_labels[0].numpy()\n",
    "#for i,j in test_data:\n",
    "#    print(i, j)\n",
    "        #print(\"Test Data Tensor:\", i)\n",
    "        #print(\"Test Data Tensor Length:\", len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 4084 33198 38012 ...     0     0     0]\n",
      " [21555 19148 14138 ...     0     0     0]\n",
      " [ 8385 28870  2424 ...     0     0     0]\n",
      " ...\n",
      " [19235 23533 28153 ...     0     0     0]\n",
      " [22979 32151 30038 ...     0     0     0]\n",
      " [33233 28168  6615 ...     0     0     0]], shape=(25, 1615), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 4084, 33198, 38012, ...,     0,     0,     0]), 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text, sample_labels = next(iter(test_data))\n",
    "\n",
    "print(sample_text)\n",
    "sample_text[0].numpy(), sample_labels[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "     64/Unknown - 646s 10s/step - loss: 0.7055 - accuracy: 0.5000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n",
      "64/64 [==============================] - 676s 11s/step - loss: 0.7055 - accuracy: 0.5000 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "16/16 [==============================] - 26s 2s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Test Loss: 0.6931550316512585\n",
      "Test Accuracy: 0.5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_graphs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-cebbc15dd245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Accuracy: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_graphs' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_data, epochs=3,\n",
    "                    validation_data=test_data,\n",
    "                    validation_steps=30)\n",
    "test_loss, test_acc = model.evaluate(test_data)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "#plot_graphs(history, 'accuracy')\n",
    "#plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "64/64 [==============================] - 63s 992ms/step - loss: 1.1232 - accuracy: 0.4694 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.9215 - accuracy: 0.5000 - val_loss: 0.8854 - val_accuracy: 0.5000\n",
      "Epoch 3/3\n",
      "64/64 [==============================] - 54s 843ms/step - loss: 0.8819 - accuracy: 0.5000 - val_loss: 0.8742 - val_accuracy: 0.5000\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 0.8742 - accuracy: 0.5000\n",
      "\n",
      "Eval loss: 0.874, Eval accuracy: 0.500\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "model = tf.keras.Sequential()\n",
    "pool_size = 4\n",
    "filters = 64\n",
    "kernel_size = 5\n",
    "\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, 8))\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "#model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=pool_size))\n",
    "#model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50)))\n",
    "#for units in [50, 50]:\n",
    "#    model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "model.add(tf.keras.layers.LSTM(50))\n",
    "model.add(tf.keras.layers.Dense(3))\n",
    "model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_data, epochs=3, validation_data=test_data)\n",
    "eval_loss, eval_acc = model.evaluate(test_data)\n",
    "\n",
    "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Tensor: (<tf.Tensor: id=102825, shape=(25, 1615), dtype=int64, numpy=\n",
      "array([[ 4084, 33198, 38012, ...,     0,     0,     0],\n",
      "       [21555, 19148, 14138, ...,     0,     0,     0],\n",
      "       [ 8385, 28870,  2424, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [19235, 23533, 28153, ...,     0,     0,     0],\n",
      "       [22979, 32151, 30038, ...,     0,     0,     0],\n",
      "       [33233, 28168,  6615, ...,     0,     0,     0]])>, <tf.Tensor: id=102826, shape=(25,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=103464, shape=(25, 1216), dtype=int64, numpy=\n",
      "array([[ 4381, 13535, 37329, ...,     0,     0,     0],\n",
      "       [13535, 34260,  8614, ...,     0,     0,     0],\n",
      "       [21555, 13535,   823, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [14325, 25795, 37077, ...,     0,     0,     0],\n",
      "       [  108, 38012, 29054, ...,     0,     0,     0],\n",
      "       [34252, 13271, 26258, ...,     0,     0,     0]])>, <tf.Tensor: id=103465, shape=(25,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=104102, shape=(25, 1610), dtype=int64, numpy=\n",
      "array([[32927,  1367, 23533, ...,     0,     0,     0],\n",
      "       [15318,  4479,  2149, ...,     0,     0,     0],\n",
      "       [13535, 37189,  8614, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [30528, 26258, 39465, ...,     0,     0,     0],\n",
      "       [38476, 23533, 23449, ...,     0,     0,     0],\n",
      "       [13535, 13393, 23533, ...,     0,     0,     0]])>, <tf.Tensor: id=104103, shape=(25,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=104740, shape=(25, 1339), dtype=int64, numpy=\n",
      "array([[27713, 10988, 32223, ...,     0,     0,     0],\n",
      "       [14878, 14664, 31526, ..., 14901, 13632,  9603],\n",
      "       [28684, 36990, 23533, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [19235,  2424, 10988, ...,     0,     0,     0],\n",
      "       [15780,  2424,  7178, ...,     0,     0,     0],\n",
      "       [28297, 19037,   108, ...,     0,     0,     0]])>, <tf.Tensor: id=104741, shape=(25,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=105378, shape=(25, 1119), dtype=int64, numpy=\n",
      "array([[34252,  8614, 13535, ...,     0,     0,     0],\n",
      "       [38899, 32151,  9630, ...,     0,     0,     0],\n",
      "       [16119, 23837, 28523, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [14736, 14961,  7620, ...,     0,     0,     0],\n",
      "       [24824, 28331, 22551, ...,     0,     0,     0],\n",
      "       [ 9045,  3179,  4476, ...,     0,     0,     0]])>, <tf.Tensor: id=105379, shape=(25,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _make_execution_function.<locals>.distributed_function at 0x646f74cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=106016, shape=(25, 1831), dtype=int64, numpy=\n",
      "array([[27171, 31985,  2424, ...,     0,     0,     0],\n",
      "       [14878, 16878,  4802, ...,     0,     0,     0],\n",
      "       [16612, 27677, 15612, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [27241, 27282, 23642, ...,     0,     0,     0],\n",
      "       [28297,  6265,  4479, ...,     0,     0,     0],\n",
      "       [ 2104, 12267,  2146, ...,     0,     0,     0]])>, <tf.Tensor: id=106017, shape=(25,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _make_execution_function.<locals>.distributed_function at 0x646f74cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=106654, shape=(25, 1205), dtype=int64, numpy=\n",
      "array([[23486, 36301, 33262, ...,     0,     0,     0],\n",
      "       [37926,   101, 36515, ...,     0,     0,     0],\n",
      "       [ 9207, 14325, 37077, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [21846, 24894,  1367, ...,     0,     0,     0],\n",
      "       [20036, 39311, 11688, ...,     0,     0,     0],\n",
      "       [36466, 37926, 13535, ...,     0,     0,     0]])>, <tf.Tensor: id=106655, shape=(25,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function _make_execution_function.<locals>.distributed_function at 0x646f74cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=107292, shape=(25, 1217), dtype=int64, numpy=\n",
      "array([[15780, 31927, 10988, ...,     0,     0,     0],\n",
      "       [ 8614, 21846, 13535, ...,     0,     0,     0],\n",
      "       [28168,  6615, 20422, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [26129,   610, 23533, ...,     0,     0,     0],\n",
      "       [11948, 34252,  8614, ...,     0,     0,     0],\n",
      "       [17742, 37626,  2182, ...,     0,     0,     0]])>, <tf.Tensor: id=107293, shape=(25,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function _make_execution_function.<locals>.distributed_function at 0x646f74cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=107930, shape=(25, 1159), dtype=int64, numpy=\n",
      "array([[34252,  8614, 13535, ...,  4479,  7255, 22551],\n",
      "       [27212, 14325, 23642, ...,     0,     0,     0],\n",
      "       [34068, 28682, 12059, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [30048, 13535, 35502, ...,     0,     0,     0],\n",
      "       [17681, 16603,  9735, ...,     0,     0,     0],\n",
      "       [ 5014,  2387,  8614, ...,     0,     0,     0]])>, <tf.Tensor: id=107931, shape=(25,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 9 calls to <function _make_execution_function.<locals>.distributed_function at 0x646f74cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=108568, shape=(25, 1185), dtype=int64, numpy=\n",
      "array([[35949, 37926,  4921, ...,     0,     0,     0],\n",
      "       [ 3539, 22619, 23533, ...,     0,     0,     0],\n",
      "       [11569,  2424, 10988, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [31424, 37926, 13535, ...,     0,     0,     0],\n",
      "       [25379, 23533, 26258, ...,     0,     0,     0],\n",
      "       [24440, 13260, 23486, ...,     0,     0,     0]])>, <tf.Tensor: id=108569, shape=(25,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function _make_execution_function.<locals>.distributed_function at 0x646f74cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=109206, shape=(25, 951), dtype=int64, numpy=\n",
      "array([[13712, 10763, 26055, ...,     0,     0,     0],\n",
      "       [34252,  8614, 13535, ...,     0,     0,     0],\n",
      "       [17742, 10787, 13276, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [ 4479,  6265, 13535, ...,     0,     0,     0],\n",
      "       [22979, 33114,   386, ...,     0,     0,     0],\n",
      "       [31848,  8635,   137, ...,     0,     0,     0]])>, <tf.Tensor: id=109207, shape=(25,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function _make_execution_function.<locals>.distributed_function at 0x646f74cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=109844, shape=(25, 1078), dtype=int64, numpy=\n",
      "array([[13535,  5014, 19492, ...,     0,     0,     0],\n",
      "       [37926, 15905, 18348, ...,     0,     0,     0],\n",
      "       [13535,   141, 16128, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [14736, 39387, 34676, ...,     0,     0,     0],\n",
      "       [15780,  3920,  3008, ...,     0,     0,     0],\n",
      "       [13101, 31546, 12635, ...,     0,     0,     0]])>, <tf.Tensor: id=109845, shape=(25,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function _make_execution_function.<locals>.distributed_function at 0x646f74cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=110482, shape=(25, 1303), dtype=int64, numpy=\n",
      "array([[ 9207, 37631, 10988, ..., 31798,  2038, 19589],\n",
      "       [23033, 20246, 23486, ...,     0,     0,     0],\n",
      "       [17742, 25622, 28363, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [29264, 16326, 29264, ...,     0,     0,     0],\n",
      "       [17742, 25622,  9502, ...,     0,     0,     0],\n",
      "       [13535, 28742,  4187, ...,     0,     0,     0]])>, <tf.Tensor: id=110483, shape=(25,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function _make_execution_function.<locals>.distributed_function at 0x646f74cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=111120, shape=(25, 1589), dtype=int64, numpy=\n",
      "array([[23486, 12901, 26535, ...,     0,     0,     0],\n",
      "       [22853, 13535, 27308, ...,     0,     0,     0],\n",
      "       [14664, 19073, 28682, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [17742, 19211, 13535, ...,     0,     0,     0],\n",
      "       [37818, 21555,  2149, ...,     0,     0,     0],\n",
      "       [19335, 13271, 28331, ...,     0,     0,     0]])>, <tf.Tensor: id=111121, shape=(25,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function _make_execution_function.<locals>.distributed_function at 0x646f74cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=111758, shape=(25, 1305), dtype=int64, numpy=\n",
      "array([[37611, 24013, 23533, ...,     0,     0,     0],\n",
      "       [ 8385, 28870,  2424, ...,     0,     0,     0],\n",
      "       [13535, 30029,  3047, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [32927,  1367, 23533, ...,     0,     0,     0],\n",
      "       [14736, 10988,  9394, ...,     0,     0,     0],\n",
      "       [10904,  5014, 12628, ...,     0,     0,     0]])>, <tf.Tensor: id=111759, shape=(25,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function _make_execution_function.<locals>.distributed_function at 0x646f74cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test Data Tensor: (<tf.Tensor: id=112396, shape=(25, 1206), dtype=int64, numpy=\n",
      "array([[13535, 30575, 18364, ...,     0,     0,     0],\n",
      "       [10988,  5064, 23086, ...,     0,     0,     0],\n",
      "       [35261, 21555, 30048, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [23177, 12026, 17500, ...,     0,     0,     0],\n",
      "       [19235,  2424,  5083, ..., 38422, 13535, 33108],\n",
      "       [ 2753, 14325, 37626, ...,     0,     0,     0]])>, <tf.Tensor: id=112397, shape=(25,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0], dtype=int32)>)\n",
      "Test Data Tensor Length: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function _make_execution_function.<locals>.distributed_function at 0x646f74cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#embedding_layer = layers.Embedding(1000, 5)\n",
    "##result = embedding_layer(tf.constant([1,2,3]))\n",
    "#result.numpy()\n",
    "#result = embedding_layer(tf.constant([[0,1,2],[3,4,5]]))\n",
    "#result.shape\n",
    "for i in test_data:\n",
    "    print(\"Test Data Tensor:\", i)\n",
    "    print(\"Test Data Tensor Length:\", len(i))\n",
    "    print(\"Prediction:\", model.predict_classes(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
